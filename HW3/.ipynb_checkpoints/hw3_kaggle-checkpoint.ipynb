{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCfOAvvpXHaH"
   },
   "source": [
    "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3. \n",
    "\n",
    "## –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç–µ–ª—è –ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–∑—ã–≤–∞.\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –±—É–¥–µ—Ç –æ–±—É—á–∏—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫—ç–≥–≥–ª–∞ –∏ –∑–∞—Å–ª–∞—Ç—å –≤ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ](https://www.kaggle.com/t/325e82797935464aa07c254b3cc3d8ad) –ø—Ä–µ–¥–∏–∫—Ç. –ß—Ç–æ–±—ã –∫–æ–Ω—Ç–µ—Å—Ç –æ—Ç–æ–±—Ä–∞–∂–∞–ª—Å—è, –æ—Ç–∫—Ä–æ–π—Ç–µ –∏ –ø—Ä–∏–º–∏—Ç–µ —É—Å–ª–æ–≤–∏—è —É—á–∞—Å—Ç–∏—è –≤ –∫–æ–Ω—Ç–µ—Å—Ç–µ —á–µ—Ä–µ–∑ —Å—Å—ã–ª–∫—É-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª–µ. –ü–æ —Ç–æ–π –∂–µ —Å—Å—ã–ª–∫–µ –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz-JIchOXHaK"
   },
   "source": [
    "–ú—ã —Å–æ–±—Ä–∞–ª–∏ –¥–ª—è –≤–∞—Å –æ—Ç–∑—ã–≤—ã –ø–æ 1500 –æ—Ç–µ–ª—è–º –∏–∑ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã—Ö —É–≥–æ–ª–∫–æ–≤ –º–∏—Ä–∞. –ß—Ç–æ —ç—Ç–æ –∑–∞ –æ—Ç–µ–ª–∏ - —Å–µ–∫—Ä–µ—Ç. –í–∞–º –¥–∞–Ω —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–µ–ª—è. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –Ω–∞—É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ –æ—Ç–∑—ã–≤—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7L3cOQLiXHaK"
   },
   "source": [
    "–ì–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ - Mean Absolute Error (MAE). –í–æ –≤—Å–µ—Ö —á–∞—Å—Ç—è—Ö –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –≤–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ MAE –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–µ–µ 0.92 –Ω–∞ –ø—É–±–ª–∏—á–Ω–æ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ. –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã –±—É–¥–µ–º –≤—ã–Ω—É–∂–¥–µ–Ω—ã –Ω–µ –∑–∞—Å—á–∏—Ç–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7rLZ12XHaM"
   },
   "source": [
    "#### –ü—Ä–æ –¥–∞–Ω–Ω—ã–µ:\n",
    "–ö–∞–∂–¥–æ–µ —Ä–µ–≤—å—é —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤: positive –∏ negative - –ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã –æ—Ç–µ–ª—è. –í —Å—Ç–æ–ª–±—Ü–µ score –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ 0 –¥–æ 10. –í–∞–º –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —ç—Ç–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –Ω–∏–º –æ—Ü–µ–Ω–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7N2muuMaGgF"
   },
   "source": [
    "–î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdKbQvpcXHaM"
   },
   "source": [
    "Good luck & have fun! üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6Ej16t1XHaM"
   },
   "source": [
    "#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–∞–º–∏ —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ. –í –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4Gc4Go5XHaN"
   },
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN_DATA = 'data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "6kJRM6ZUXHaO",
    "outputId": "2c0aabd7-5e62-44a6-bf54-0960af80d435"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9ceb0c2f-fa50-49eb-bec1-a39c9380e160\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ceb0c2f-fa50-49eb-bec1-a39c9380e160')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9ceb0c2f-fa50-49eb-bec1-a39c9380e160 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9ceb0c2f-fa50-49eb-bec1-a39c9380e160');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                          review_id  ... score\n",
       "0  00003c6036f30f590c0ac435efb8739b  ...   7.1\n",
       "1  00004d18f186bf2489590dc415876f73  ...   7.5\n",
       "2  0000cf900cbb8667fad33a717e9b1cf4  ...  10.0\n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e  ...   5.4\n",
       "4  00025e1aa3ac32edb496db49e76bbd00  ...   6.7\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpLk8dXBXHaP"
   },
   "source": [
    "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç —Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏.\n",
    "–°–¥–µ–ª–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤: —É–¥–∞–ª–∏–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –ø—Ä–∏–≤–µ–¥–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É. \n",
    "–û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å—Å—è —ç—Ç–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π. –ü–æ–¥—É–º–∞–π—Ç–µ, —á—Ç–æ –µ—â–µ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –±—É–¥—É—â–∏–º –º–æ–¥–µ–ª—è–º? –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–º–æ—á—å –ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfkhII5AXHaP"
   },
   "source": [
    "–¢–∞–∫–∂–µ –º—ã –¥–æ–±–∞–≤–∏–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ç–æ–∫–µ–Ω—ã. –¢–µ–ø–µ—Ä—å –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–µ–≤—å—é —Å—Ç–∞–ª–∞ –º–∞—Å—Å–∏–≤–æ–º —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tv-gbEKGXHaQ",
    "outputId": "17d138ba-56d4-46fa-ad98-346e0683817c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def process_text(text):\n",
    "    return [word for word in word_tokenize(text.lower()) if word not in string.punctuation] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X1bXhROXHaQ"
   },
   "outputs": [],
   "source": [
    "df['negative'] = df['negative'].apply(process_text)\n",
    "df['positive'] = df['positive'].apply(process_text)\n",
    "\n",
    "df['negative'] = df['negative'].apply(lambda x: [l + '-' for l in x])\n",
    "df['positive'] = df['positive'].apply(lambda x: [l + '+' for l in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MewBIvp9XHaQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, random_state=1412) # <- –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gu1EIc3XHaR"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 1. 1 –±–∞–ª–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM7ZD9gyXHaR"
   },
   "source": [
    "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ TF-IDF –≤–µ–∫—Ç–æ—Ä–∞—Ö —Ç–µ–∫—Å—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2x4yCjh8XHaR"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhJ9D0dZuA64"
   },
   "outputs": [],
   "source": [
    "def join_tokens(tokens):\n",
    "    return re.sub(r'\\d+', '', ' '.join(tokens))\n",
    "\n",
    "def prepare_data(df_train, df_test):\n",
    "    X_train = df_train['negative'].apply(join_tokens) + ' ' + df_train['positive'].apply(join_tokens)\n",
    "    X_test = df_test['negative'].apply(join_tokens) + ' ' + df_test['positive'].apply(join_tokens)\n",
    "    \n",
    "    y_train = df_train['score']\n",
    "    y_test = df_test['score']\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeaE2ywBuA65"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_data(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZXLovqMuA65"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, analyzer='char',\n",
    "                        stop_words= 'english',ngram_range=(1,2))\n",
    "\n",
    "# Word ngram vector\n",
    "tr_vect = vectorizer.fit_transform(X_train)\n",
    "ts_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooSPwXUxuA65",
    "outputId": "0bff009b-db12-4af6-837a-71e8d2343f2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9189446614427927"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "regressor = LinearRegression(n_jobs=4)\n",
    "regressor.fit(tr_vect, y_train)\n",
    "y_predicted = regressor.predict(ts_vect)\n",
    "\n",
    "mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "TUBmZGikuA66",
    "outputId": "27621e27-1908-4fb2-ad65-9c5503c1f867"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fb3342e2-3f36-43b7-b6c1-a4690cd0ba86\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00026f564b258ad5159aab07c357c4ca</td>\n",
       "      <td>Other than the location everything else was h...</td>\n",
       "      <td>Just the location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000278c73da08f4fcb857fcfe4ac6417</td>\n",
       "      <td>No UK TV but this was a minor point as we wer...</td>\n",
       "      <td>Great location very comfortable clean breakfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000404f843e756fe3b2a477dbefa5bd4</td>\n",
       "      <td>A tiny noisy room VERY deceptively photographed</td>\n",
       "      <td>The breakfast booked the preceding night but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a66d32bcf305148d789ac156dd512</td>\n",
       "      <td>Noisy various electrical devices kicking in r...</td>\n",
       "      <td>Great location Nice bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000bf1d8c5110701f459ffbedbf0d546</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Great location and friendly staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb3342e2-3f36-43b7-b6c1-a4690cd0ba86')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fb3342e2-3f36-43b7-b6c1-a4690cd0ba86 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fb3342e2-3f36-43b7-b6c1-a4690cd0ba86');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                          review_id  ...                                           positive\n",
       "0  00026f564b258ad5159aab07c357c4ca  ...                                 Just the location \n",
       "1  000278c73da08f4fcb857fcfe4ac6417  ...   Great location very comfortable clean breakfa...\n",
       "2  000404f843e756fe3b2a477dbefa5bd4  ...   The breakfast booked the preceding night but ...\n",
       "3  000a66d32bcf305148d789ac156dd512  ...                       Great location Nice bathroom\n",
       "4  000bf1d8c5110701f459ffbedbf0d546  ...                  Great location and friendly staff\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv(\"data/test.csv\")\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H35E9OkUuA66"
   },
   "outputs": [],
   "source": [
    "df_kaggle['negative'] = df_kaggle['negative'].apply(process_text)\n",
    "df_kaggle['positive'] = df_kaggle['positive'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1phOoMAuA66"
   },
   "outputs": [],
   "source": [
    "test_kaggle = df_kaggle['negative'].apply(join_tokens) + ' ' + df_kaggle['positive'].apply(join_tokens)\n",
    "test_kaggle_vect = vectorizer.transform(test_kaggle)\n",
    "y_kaggle_predicted = regressor.predict(test_kaggle_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "gRcMuH4YuA67",
    "outputId": "f498755b-e6fa-40c0-a95c-5c429afe1fb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fcdd90e2-8585-4f46-8077-9cca3586e926\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00026f564b258ad5159aab07c357c4ca</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000278c73da08f4fcb857fcfe4ac6417</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000404f843e756fe3b2a477dbefa5bd4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a66d32bcf305148d789ac156dd512</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000bf1d8c5110701f459ffbedbf0d546</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>ffe8a7190aee6e3a53ee2e0145a91555</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>ffea0e2b84788c9df755efe8e2bedb23</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>fff3997a85a1eed7ae7a937bc945fcf0</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>fff673fe95ab8f3a0910f112549862e2</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>fffde0b07729c476fa6509524cf07f15</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows √ó 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcdd90e2-8585-4f46-8077-9cca3586e926')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fcdd90e2-8585-4f46-8077-9cca3586e926 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fcdd90e2-8585-4f46-8077-9cca3586e926');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                              review_id  score\n",
       "0      00026f564b258ad5159aab07c357c4ca    3.5\n",
       "1      000278c73da08f4fcb857fcfe4ac6417    5.2\n",
       "2      000404f843e756fe3b2a477dbefa5bd4    4.0\n",
       "3      000a66d32bcf305148d789ac156dd512    4.3\n",
       "4      000bf1d8c5110701f459ffbedbf0d546    5.3\n",
       "...                                 ...    ...\n",
       "19995  ffe8a7190aee6e3a53ee2e0145a91555    3.9\n",
       "19996  ffea0e2b84788c9df755efe8e2bedb23    5.0\n",
       "19997  fff3997a85a1eed7ae7a937bc945fcf0    5.1\n",
       "19998  fff673fe95ab8f3a0910f112549862e2    3.8\n",
       "19999  fffde0b07729c476fa6509524cf07f15    5.0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answer_kaggle = df_kaggle[\"review_id\"].to_frame()\n",
    "df_answer_kaggle[\"score\"] = y_kaggle_predicted.round(1).tolist()\n",
    "df_answer_kaggle.to_csv(\"data/submission.csv\", index=False)\n",
    "\n",
    "df_answer_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CufFcfHXhuo"
   },
   "source": [
    "–ü—Ä–µ–¥—Å–∫–∞–∂–∏—Ç–µ —ç—Ç–æ–π –º–æ–¥–µ–ª—å—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è](https://www.kaggle.com/t/325e82797935464aa07c254b3cc3d8ad) –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª—Å—è —Å–∫–æ—Ä? –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫—ç–≥–≥–ª–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbuwYR6BuA67"
   },
   "source": [
    "![](https://i.imgur.com/v7e1HMQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-4Zve40XHaS"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 2. 2 –±–∞–ª–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYFL-5yFXHaS"
   },
   "source": [
    "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã—Ö Word2Vec –≤–µ–∫—Ç–æ—Ä–∞—Ö. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rTy4WgJZuA67",
    "outputId": "73d9c064-ba99-45e1-abae-f97ab35b561c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4f68dbae-e147-44a4-b8e8-df734c389055\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f68dbae-e147-44a4-b8e8-df734c389055')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4f68dbae-e147-44a4-b8e8-df734c389055 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4f68dbae-e147-44a4-b8e8-df734c389055');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                          review_id  ... score\n",
       "0  00003c6036f30f590c0ac435efb8739b  ...   7.1\n",
       "1  00004d18f186bf2489590dc415876f73  ...   7.5\n",
       "2  0000cf900cbb8667fad33a717e9b1cf4  ...  10.0\n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e  ...   5.4\n",
       "4  00025e1aa3ac32edb496db49e76bbd00  ...   6.7\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8-Cf8TyuA68"
   },
   "outputs": [],
   "source": [
    "df['opinion'] = df['positive'].str.cat(df['negative'], sep =\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXtS7dBWuA68"
   },
   "outputs": [],
   "source": [
    "df['opinion'] = df['opinion'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ap_LXBAwuA68"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, random_state=1412) # <- –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpcCEhBDXHaS"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MfwLa9HuA68",
    "outputId": "31682ed7-89ef-42c5-dd05-007e99a5e261"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:52:51: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=500, alpha=0.03)', 'datetime': '2021-12-19T23:52:51.641997', 'gensim': '4.1.2', 'python': '3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-21.1.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "EMB_SIZE = 500\n",
    "\n",
    "w2v_model = Word2Vec(min_count=1,\n",
    "                     window=2,\n",
    "                     vector_size=EMB_SIZE,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mi2DqZ45uA69",
    "outputId": "1e3a2a3c-14b5-4ab2-ac10-6a5fcf3a4b5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:52:51: collecting all words and their counts\n",
      "INFO - 23:52:51: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 23:52:52: PROGRESS: at sentence #50000, processed 1726357 words, keeping 24704 word types\n",
      "INFO - 23:52:52: collected 34728 word types from a corpus of 3440696 raw words and 100000 sentences\n",
      "INFO - 23:52:52: Creating a fresh vocabulary\n",
      "INFO - 23:52:52: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 34728 unique words (100.0%% of original 34728, drops 0)', 'datetime': '2021-12-19T23:52:52.504780', 'gensim': '4.1.2', 'python': '3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-21.1.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 23:52:52: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3440696 word corpus (100.0%% of original 3440696, drops 0)', 'datetime': '2021-12-19T23:52:52.505421', 'gensim': '4.1.2', 'python': '3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-21.1.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 23:52:52: deleting the raw counts dictionary of 34728 items\n",
      "INFO - 23:52:52: sample=6e-05 downsamples 678 most-common words\n",
      "INFO - 23:52:52: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1153884.8848770016 word corpus (33.5%% of prior 3440696)', 'datetime': '2021-12-19T23:52:52.714624', 'gensim': '4.1.2', 'python': '3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-21.1.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 23:52:53: estimated required memory for 34728 words and 500 dimensions: 156276000 bytes\n",
      "INFO - 23:52:53: resetting layer weights\n",
      "INFO - 23:52:53: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-12-19T23:52:53.217957', 'gensim': '4.1.2', 'python': '3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-21.1.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "INFO - 23:52:53: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 34728 vocabulary and 500 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2021-12-19T23:52:53.218984', 'gensim': '4.1.2', 'python': '3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-21.1.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO - 23:52:54: EPOCH 1 - PROGRESS: at 30.31% examples, 347936 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:52:55: EPOCH 1 - PROGRESS: at 70.31% examples, 401864 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:52:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:52:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:52:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:52:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:52:56: EPOCH - 1 : training on 3440696 raw words (1154146 effective words) took 2.9s, 399338 effective words/s\n",
      "INFO - 23:52:57: EPOCH 2 - PROGRESS: at 40.07% examples, 462802 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:52:58: EPOCH 2 - PROGRESS: at 80.22% examples, 461711 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:52:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:52:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:52:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:52:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:52:58: EPOCH - 2 : training on 3440696 raw words (1152716 effective words) took 2.5s, 462647 effective words/s\n",
      "INFO - 23:52:59: EPOCH 3 - PROGRESS: at 37.13% examples, 423626 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:00: EPOCH 3 - PROGRESS: at 78.00% examples, 446167 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:01: EPOCH - 3 : training on 3440696 raw words (1153714 effective words) took 2.5s, 453934 effective words/s\n",
      "INFO - 23:53:02: EPOCH 4 - PROGRESS: at 33.39% examples, 387305 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:03: EPOCH 4 - PROGRESS: at 76.83% examples, 444011 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:03: EPOCH - 4 : training on 3440696 raw words (1154544 effective words) took 2.7s, 427033 effective words/s\n",
      "INFO - 23:53:04: EPOCH 5 - PROGRESS: at 41.87% examples, 477086 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:05: EPOCH 5 - PROGRESS: at 84.06% examples, 481282 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:06: EPOCH - 5 : training on 3440696 raw words (1154306 effective words) took 2.4s, 481887 effective words/s\n",
      "INFO - 23:53:07: EPOCH 6 - PROGRESS: at 35.97% examples, 410478 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:08: EPOCH 6 - PROGRESS: at 77.13% examples, 440977 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:53:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:08: EPOCH - 6 : training on 3440696 raw words (1153966 effective words) took 2.6s, 445893 effective words/s\n",
      "INFO - 23:53:09: EPOCH 7 - PROGRESS: at 40.07% examples, 462854 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:10: EPOCH 7 - PROGRESS: at 84.33% examples, 486417 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:11: EPOCH - 7 : training on 3440696 raw words (1153981 effective words) took 2.4s, 487751 effective words/s\n",
      "INFO - 23:53:12: EPOCH 8 - PROGRESS: at 35.37% examples, 410320 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:13: EPOCH 8 - PROGRESS: at 73.19% examples, 422248 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:14: EPOCH - 8 : training on 3440696 raw words (1153593 effective words) took 2.8s, 414164 effective words/s\n",
      "INFO - 23:53:15: EPOCH 9 - PROGRESS: at 35.97% examples, 415725 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:16: EPOCH 9 - PROGRESS: at 70.31% examples, 404078 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:53:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:16: EPOCH - 9 : training on 3440696 raw words (1153258 effective words) took 2.8s, 417929 effective words/s\n",
      "INFO - 23:53:17: EPOCH 10 - PROGRESS: at 41.87% examples, 480750 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:18: EPOCH 10 - PROGRESS: at 78.82% examples, 453104 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:53:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:19: EPOCH - 10 : training on 3440696 raw words (1154421 effective words) took 2.6s, 439610 effective words/s\n",
      "INFO - 23:53:20: EPOCH 11 - PROGRESS: at 43.29% examples, 495514 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:21: EPOCH 11 - PROGRESS: at 81.12% examples, 466175 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:21: EPOCH - 11 : training on 3440696 raw words (1153860 effective words) took 2.5s, 456952 effective words/s\n",
      "INFO - 23:53:22: EPOCH 12 - PROGRESS: at 43.29% examples, 495824 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:24: EPOCH 12 - PROGRESS: at 83.74% examples, 480143 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:24: EPOCH - 12 : training on 3440696 raw words (1153840 effective words) took 2.5s, 463216 effective words/s\n",
      "INFO - 23:53:25: EPOCH 13 - PROGRESS: at 31.73% examples, 365667 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:26: EPOCH 13 - PROGRESS: at 76.55% examples, 439951 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:27: EPOCH - 13 : training on 3440696 raw words (1154084 effective words) took 2.7s, 432421 effective words/s\n",
      "INFO - 23:53:28: EPOCH 14 - PROGRESS: at 44.14% examples, 508264 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:53:29: EPOCH 14 - PROGRESS: at 89.56% examples, 515931 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:29: EPOCH - 14 : training on 3440696 raw words (1153716 effective words) took 2.2s, 515410 effective words/s\n",
      "INFO - 23:53:30: EPOCH 15 - PROGRESS: at 35.97% examples, 412228 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:31: EPOCH 15 - PROGRESS: at 78.55% examples, 451875 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:31: EPOCH - 15 : training on 3440696 raw words (1154924 effective words) took 2.5s, 465817 effective words/s\n",
      "INFO - 23:53:32: EPOCH 16 - PROGRESS: at 34.75% examples, 396605 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:33: EPOCH 16 - PROGRESS: at 76.28% examples, 436695 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:34: EPOCH - 16 : training on 3440696 raw words (1153108 effective words) took 2.8s, 408621 effective words/s\n",
      "INFO - 23:53:35: EPOCH 17 - PROGRESS: at 42.15% examples, 485448 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:53:36: EPOCH 17 - PROGRESS: at 87.00% examples, 500117 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:37: EPOCH - 17 : training on 3440696 raw words (1154203 effective words) took 2.3s, 504742 effective words/s\n",
      "INFO - 23:53:38: EPOCH 18 - PROGRESS: at 44.14% examples, 509851 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:39: EPOCH 18 - PROGRESS: at 89.56% examples, 516659 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:39: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:39: EPOCH - 18 : training on 3440696 raw words (1153352 effective words) took 2.2s, 518027 effective words/s\n",
      "INFO - 23:53:40: EPOCH 19 - PROGRESS: at 30.84% examples, 355977 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:41: EPOCH 19 - PROGRESS: at 65.97% examples, 378729 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:42: EPOCH - 19 : training on 3440696 raw words (1154101 effective words) took 3.0s, 385251 effective words/s\n",
      "INFO - 23:53:43: EPOCH 20 - PROGRESS: at 38.62% examples, 446864 words/s, in_qsize 8, out_qsize 2\n",
      "INFO - 23:53:44: EPOCH 20 - PROGRESS: at 81.42% examples, 470484 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:44: EPOCH - 20 : training on 3440696 raw words (1153243 effective words) took 2.5s, 465758 effective words/s\n",
      "INFO - 23:53:45: EPOCH 21 - PROGRESS: at 39.22% examples, 454197 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:46: EPOCH 21 - PROGRESS: at 78.00% examples, 450521 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:47: EPOCH - 21 : training on 3440696 raw words (1154492 effective words) took 2.6s, 451447 effective words/s\n",
      "INFO - 23:53:48: EPOCH 22 - PROGRESS: at 30.84% examples, 356369 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:49: EPOCH 22 - PROGRESS: at 70.31% examples, 405306 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:50: EPOCH - 22 : training on 3440696 raw words (1153796 effective words) took 2.8s, 408261 effective words/s\n",
      "INFO - 23:53:51: EPOCH 23 - PROGRESS: at 39.80% examples, 460362 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:52: EPOCH 23 - PROGRESS: at 71.20% examples, 409866 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:52: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:53:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:52: EPOCH - 23 : training on 3440696 raw words (1154075 effective words) took 2.8s, 406441 effective words/s\n",
      "INFO - 23:53:54: EPOCH 24 - PROGRESS: at 32.85% examples, 376047 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:55: EPOCH 24 - PROGRESS: at 68.86% examples, 392233 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:55: EPOCH - 24 : training on 3440696 raw words (1154308 effective words) took 2.8s, 414831 effective words/s\n",
      "INFO - 23:53:56: EPOCH 25 - PROGRESS: at 35.97% examples, 414450 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:53:57: EPOCH 25 - PROGRESS: at 70.03% examples, 402252 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:53:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:53:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:58: EPOCH - 25 : training on 3440696 raw words (1152913 effective words) took 2.7s, 420966 effective words/s\n",
      "INFO - 23:53:59: EPOCH 26 - PROGRESS: at 27.97% examples, 317764 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:00: EPOCH 26 - PROGRESS: at 55.83% examples, 315863 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:54:01: EPOCH 26 - PROGRESS: at 82.83% examples, 315121 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:01: EPOCH - 26 : training on 3440696 raw words (1153895 effective words) took 3.5s, 334330 effective words/s\n",
      "INFO - 23:54:03: EPOCH 27 - PROGRESS: at 39.80% examples, 461470 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:54:04: EPOCH 27 - PROGRESS: at 79.94% examples, 458556 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:54:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:04: EPOCH - 27 : training on 3440696 raw words (1154549 effective words) took 2.7s, 430715 effective words/s\n",
      "INFO - 23:54:05: EPOCH 28 - PROGRESS: at 33.65% examples, 388073 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:06: EPOCH 28 - PROGRESS: at 68.58% examples, 391668 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:54:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:07: EPOCH - 28 : training on 3440696 raw words (1153642 effective words) took 2.9s, 394309 effective words/s\n",
      "INFO - 23:54:08: EPOCH 29 - PROGRESS: at 38.62% examples, 441317 words/s, in_qsize 7, out_qsize 1\n",
      "INFO - 23:54:09: EPOCH 29 - PROGRESS: at 78.00% examples, 445614 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:54:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:10: EPOCH - 29 : training on 3440696 raw words (1153394 effective words) took 2.7s, 422135 effective words/s\n",
      "INFO - 23:54:11: EPOCH 30 - PROGRESS: at 27.68% examples, 318817 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:12: EPOCH 30 - PROGRESS: at 62.79% examples, 359138 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:13: EPOCH - 30 : training on 3440696 raw words (1153819 effective words) took 3.0s, 384188 effective words/s\n",
      "INFO - 23:54:14: EPOCH 31 - PROGRESS: at 37.45% examples, 432276 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:15: EPOCH 31 - PROGRESS: at 73.46% examples, 421361 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:16: EPOCH - 31 : training on 3440696 raw words (1153517 effective words) took 2.8s, 405385 effective words/s\n",
      "INFO - 23:54:17: EPOCH 32 - PROGRESS: at 34.75% examples, 403547 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:54:18: EPOCH 32 - PROGRESS: at 72.32% examples, 415328 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:18: EPOCH - 32 : training on 3440696 raw words (1153502 effective words) took 2.7s, 421875 effective words/s\n",
      "INFO - 23:54:20: EPOCH 33 - PROGRESS: at 37.13% examples, 423237 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:54:21: EPOCH 33 - PROGRESS: at 72.89% examples, 414633 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:22: EPOCH - 33 : training on 3440696 raw words (1154332 effective words) took 3.0s, 383016 effective words/s\n",
      "INFO - 23:54:23: EPOCH 34 - PROGRESS: at 35.97% examples, 409896 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:24: EPOCH 34 - PROGRESS: at 68.04% examples, 388193 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:54:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:24: EPOCH - 34 : training on 3440696 raw words (1153438 effective words) took 2.8s, 404837 effective words/s\n",
      "INFO - 23:54:25: EPOCH 35 - PROGRESS: at 31.73% examples, 365478 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:26: EPOCH 35 - PROGRESS: at 72.32% examples, 415545 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:27: EPOCH - 35 : training on 3440696 raw words (1153144 effective words) took 2.8s, 414654 effective words/s\n",
      "INFO - 23:54:28: EPOCH 36 - PROGRESS: at 33.65% examples, 384495 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:29: EPOCH 36 - PROGRESS: at 67.43% examples, 383014 words/s, in_qsize 7, out_qsize 1\n",
      "INFO - 23:54:30: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:30: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:54:30: EPOCH - 36 : training on 3440696 raw words (1153027 effective words) took 2.9s, 396367 effective words/s\n",
      "INFO - 23:54:31: EPOCH 37 - PROGRESS: at 34.22% examples, 396447 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 23:54:32: EPOCH 37 - PROGRESS: at 74.58% examples, 428964 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:33: EPOCH - 37 : training on 3440696 raw words (1154816 effective words) took 2.7s, 434335 effective words/s\n",
      "INFO - 23:54:34: EPOCH 38 - PROGRESS: at 39.51% examples, 455967 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:35: EPOCH 38 - PROGRESS: at 79.94% examples, 460790 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:35: EPOCH - 38 : training on 3440696 raw words (1154262 effective words) took 2.5s, 464209 effective words/s\n",
      "INFO - 23:54:36: EPOCH 39 - PROGRESS: at 39.51% examples, 452312 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:37: EPOCH 39 - PROGRESS: at 80.54% examples, 460798 words/s, in_qsize 8, out_qsize 1\n",
      "INFO - 23:54:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:38: EPOCH - 39 : training on 3440696 raw words (1152993 effective words) took 2.5s, 467000 effective words/s\n",
      "INFO - 23:54:39: EPOCH 40 - PROGRESS: at 38.32% examples, 439630 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:40: EPOCH 40 - PROGRESS: at 79.38% examples, 456922 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:40: EPOCH - 40 : training on 3440696 raw words (1154243 effective words) took 2.5s, 461457 effective words/s\n",
      "INFO - 23:54:41: EPOCH 41 - PROGRESS: at 40.38% examples, 466702 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:42: EPOCH 41 - PROGRESS: at 81.12% examples, 466339 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 23:54:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 23:54:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:54:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:54:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:54:43: EPOCH - 41 : training on 3440696 raw words (1154148 effective words) took 2.5s, 467516 effective words/s\n",
      "INFO - 23:54:44: EPOCH 42 - PROGRESS: at 38.62% examples, 442610 words/s, in_qsize 8, out_qsize 2\n",
      "INFO - 23:54:45: EPOCH 42 - PROGRESS: at 78.82% examples, 452177 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-18640aae54f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opinion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opinion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m                     \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                     callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m   1431\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m         )\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(df['opinion'], progress_per=50000)\n",
    "w2v_model.train(df['opinion'], total_examples=w2v_model.corpus_count, epochs=70, report_delay=1)\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uW36fW5CuA69",
    "outputId": "62a3ba12-6817-497a-9386-2ecf4482e3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excellent', 0.6185586452484131),\n",
       " ('great', 0.5960034132003784),\n",
       " ('nice', 0.5376293659210205),\n",
       " ('very', 0.42820680141448975),\n",
       " ('comfortable', 0.42485761642456055),\n",
       " ('clean', 0.41823825240135193),\n",
       " ('location', 0.4068338871002197),\n",
       " ('friendly', 0.405752032995224),\n",
       " ('poor', 0.398668110370636),\n",
       " ('lovely', 0.3927823305130005)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"good\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWrIciGxXHaS"
   },
   "source": [
    "–£—Å—Ä–µ–¥–Ω—è—è w2v –≤–µ–∫—Ç–æ—Ä–∞, –º—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–º–µ–µ—Ç —Ä–∞–≤–Ω–æ—Ü–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Å–º—ã—Å–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Å–æ–≤—Å–µ–º —Ç–∞–∫. –¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥—Ä—É–≥–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–µ–π –∏ –ø–µ—Ä–µ–≤–∑–≤–µ—Å–∏—Ç—å —Å–ª–æ–≤–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞. –í –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ IDF (Inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQSuuLP9XHaS"
   },
   "outputs": [],
   "source": [
    "def calc_idf(texts):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s-6HQo0XHaT"
   },
   "source": [
    "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –¥–≤—É—Ö –º–µ—Ç–æ–¥–æ–≤ –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. \n",
    "\n",
    "#### –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f29vizrmXHaT"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 300 –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å Word2Vec.\n",
    "#### –í—ã–≤–æ–¥—ã:\n",
    "`<–í–ê–® –¢–ï–ö–°–¢ –ó–î–ï–°–¨>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AjabHMsXXBu"
   },
   "source": [
    "–ü—Ä–µ–¥—Å–∫–∞–∂–∏—Ç–µ –≤–∞—à–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é –∏–∑ —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è](https://www.kaggle.com/t/325e82797935464aa07c254b3cc3d8ad) –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª—Å—è —Å–∫–æ—Ä? –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫—ç–≥–≥–ª–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO5TZriLXHaT"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 3. 4 –±–∞–ª–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RNngNdWXHaT"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –≤ –Ω–∞—à–µ–º –∫—É—Ä—Å–µ. –û–±—É—á–∏—Ç–µ RNN/Transformer –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏. –ü–æ–ª—É—á–∏—Ç–µ –æ—à–∏–±–∫—É –º–µ–Ω—å—à–µ, —á–µ–º –≤–æ –≤—Å–µ—Ö –≤—ã—à–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8YdTedQXHaT"
   },
   "source": [
    "–ï—Å–ª–∏ –±—É–¥–µ—Ç–µ –æ–±—É—á–∞—Ç—å RNN, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∑—ã–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö.\n",
    "\n",
    "–ß—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è DataLoader, –≤—Å–µ –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω—É–ª–µ–≤–æ–π –ø–∞–¥–¥–∏–Ω–≥ –∫–æ –≤—Å–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (—Å–º –ø—Ä–∏–º–µ—Ä pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-H0akvuuA6-",
    "outputId": "4746522e-ec8f-405d-a0dc-fbb4b3acc18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176 kB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.10.0+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.62.3)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 38.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 30.3 MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.20.24-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131 kB 47.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.10.0.2)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79 kB 8.3 MB/s \n",
      "\u001b[?25hCollecting botocore<1.24.0,>=1.23.24\n",
      "  Downloading botocore-1.23.24-py3-none-any.whl (8.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.4 MB 32.6 MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138 kB 39.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.24->boto3->pytorch_transformers) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3->pytorch_transformers) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127 kB 31.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.20.24 botocore-1.23.24 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89Y9wsViXHaU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pytorch_transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from pytorch_transformers import RobertaConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kYgDPRxuA6_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "df['opinion'] = df['positive'].str.cat(df['negative'], sep =\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYQgJ0CUuA6_"
   },
   "outputs": [],
   "source": [
    "set_score = list(set(df.score.tolist()))\n",
    "dict_score = {set_score[item]:item for item in range(len(set_score))}\n",
    "def get_class(score):\n",
    "    return(dict_score[score['score']])\n",
    "  \n",
    "df['reviewClass'] = df.apply(get_class, axis=1)\n",
    "\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w26ELg6juA6_"
   },
   "outputs": [],
   "source": [
    "sentences_train = [i for i in df_train['opinion']]\n",
    "labels_train = [i for i in df_train['reviewClass'].tolist()]\n",
    "\n",
    "sentences_test = [i for i in df_test['opinion']]\n",
    "labels_test = [i for i in df_test['reviewClass'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3KzoSWSuA6_",
    "outputId": "6ba2605c-2c45-494c-da30-7e86872efb3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 898823/898823 [00:00<00:00, 3257651.64B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456318/456318 [00:00<00:00, 2102723.10B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base',add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AY63yCfZuA7A",
    "outputId": "34ca1310-0f18-4082-e45e-e0b7183ca63c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 150\n",
    "train_input = [tokenizer.encode(x,add_special_tokens=True) for x in sentences_train]\n",
    "\n",
    "train_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in train_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "train_masks = [[float(i>0) for i in seq] for seq in train_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzvppoQouA7A",
    "outputId": "2035d499-6f01-40d4-e34c-771ae3aec288"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "val_input = [tokenizer.encode(x, add_special_tokens=True) for x in sentences_test]\n",
    "val_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in val_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "val_masks = [[float(i>0) for i in seq] for seq in val_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiT5MQyluA7A"
   },
   "outputs": [],
   "source": [
    "train_inputs = train_pos_pad.clone().detach()\n",
    "train_labels = torch.tensor(labels_train)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "\n",
    "val_inputs = val_pos_pad.clone().detach()\n",
    "val_labels = torch.tensor(labels_test)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wo_hUnkuA7A"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_dataloader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ve-9BQZauA7A",
    "outputId": "05d78a0d-45ef-4127-fda3-c3840290f298"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 481/481 [00:00<00:00, 262690.13B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 501200538/501200538 [00:19<00:00, 25909053.67B/s]\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(\"roberta-base\", \n",
    "                                       output_hidden_states=True, \n",
    "                                       num_labels=len(df_train.score.unique()))\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                         config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiV31DjruA7B"
   },
   "outputs": [],
   "source": [
    "dict_score_class = {item:set_score[item] for item in range(len(set_score))}\n",
    "\n",
    "def mae(predicted, actual):\n",
    "    predicted =  [dict_score_class[item] for item in predicted]\n",
    "    actual = [dict_score_class[item] for item in actual]\n",
    "    return mean_absolute_error(predicted, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "KOxaPPZyohOF",
    "outputId": "b9accd54-7bde-4acd-db91-629ae1cf2185"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b28b13ec-7666-47a2-bbd8-a234fbfe9102\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00026f564b258ad5159aab07c357c4ca</td>\n",
       "      <td>Other than the location everything else was h...</td>\n",
       "      <td>Just the location</td>\n",
       "      <td>Just the location   Other than the location e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000278c73da08f4fcb857fcfe4ac6417</td>\n",
       "      <td>No UK TV but this was a minor point as we wer...</td>\n",
       "      <td>Great location very comfortable clean breakfa...</td>\n",
       "      <td>Great location very comfortable clean breakfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000404f843e756fe3b2a477dbefa5bd4</td>\n",
       "      <td>A tiny noisy room VERY deceptively photographed</td>\n",
       "      <td>The breakfast booked the preceding night but ...</td>\n",
       "      <td>The breakfast booked the preceding night but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a66d32bcf305148d789ac156dd512</td>\n",
       "      <td>Noisy various electrical devices kicking in r...</td>\n",
       "      <td>Great location Nice bathroom</td>\n",
       "      <td>Great location Nice bathroom  Noisy various e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000bf1d8c5110701f459ffbedbf0d546</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Great location and friendly staff</td>\n",
       "      <td>Great location and friendly staff No Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b28b13ec-7666-47a2-bbd8-a234fbfe9102')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b28b13ec-7666-47a2-bbd8-a234fbfe9102 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b28b13ec-7666-47a2-bbd8-a234fbfe9102');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                          review_id  ...                                            opinion\n",
       "0  00026f564b258ad5159aab07c357c4ca  ...   Just the location   Other than the location e...\n",
       "1  000278c73da08f4fcb857fcfe4ac6417  ...   Great location very comfortable clean breakfa...\n",
       "2  000404f843e756fe3b2a477dbefa5bd4  ...   The breakfast booked the preceding night but ...\n",
       "3  000a66d32bcf305148d789ac156dd512  ...   Great location Nice bathroom  Noisy various e...\n",
       "4  000bf1d8c5110701f459ffbedbf0d546  ...      Great location and friendly staff No Negative\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv('data/test.csv')\n",
    "df_kaggle['opinion'] = df_kaggle['positive'].str.cat(df_kaggle['negative'], sep =\" \")\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OB9ejx2EoqFX"
   },
   "outputs": [],
   "source": [
    "sentences_test = [sentence for sentence in df_kaggle['opinion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgFNOp5Foqnu",
    "outputId": "9819b6f5-b1eb-4add-8d7c-df77e31d14f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 150\n",
    "test_input = [tokenizer.encode(x,add_special_tokens=True) for x in sentences_test]\n",
    "\n",
    "test_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in test_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "test_masks = [[float(i>0) for i in seq] for seq in test_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_uZCVgootqx",
    "outputId": "5e98cad8-77d7-4580-c28a-170d0210904f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_inputs = torch.tensor(test_pos_pad)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQhMtkx3ozmq"
   },
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_inputs, test_masks)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUvy-RU4uA7B"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, \n",
    "                    criterion, optimizer, device=\"cuda:0\"):\n",
    "    model.to(device).train()\n",
    "    with tqdm(total=len(train_dataloader)) as pbar:\n",
    "        for batch in train_dataloader:\n",
    "            ids, mask, labels = batch\n",
    "            ids = ids.to(device)\n",
    "            mask = mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(ids, token_type_ids=None, \n",
    "                                   attention_mask=mask)[0]\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(output.detach(), 1)\n",
    "            accuracy_mae = mae(predicted.cpu().detach().numpy(), \n",
    "                               labels.cpu().detach().numpy())\n",
    "            pbar.set_description(\n",
    "                'CrossEntropyLoss: {:.4f}; MAE: {:.4f}'.format(\n",
    "                    loss.detach().item(), accuracy_mae))    \n",
    "            pbar.update(1)\n",
    "            \n",
    "def predict(model, val_dataloader, criterion, device=\"cuda:0\"):\n",
    "    model.to(device).eval()\n",
    "    losses = []\n",
    "    predicted_classes = []\n",
    "    true_classes = []\n",
    "    with tqdm(total=len(val_dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                ids, mask, labels = batch\n",
    "                ids = ids.to(device)\n",
    "                mask = mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                \n",
    "                output = model.forward(ids, token_type_ids=None, \n",
    "                                       attention_mask=mask)[0]\n",
    "                _, predicted = torch.max(output, 1)\n",
    "            \n",
    "                loss = criterion(output, labels)\n",
    "                losses.append(loss.item())\n",
    "                _, predicted = torch.max(output.detach(), 1)\n",
    "                predicted_classes.append(predicted)\n",
    "                true_classes.append(labels)\n",
    "                \n",
    "                \n",
    "                accuracy_mae = mae(predicted.cpu().detach().numpy(), \n",
    "                                   labels.cpu().detach().numpy())\n",
    "                pbar.set_description(\n",
    "                    'CrossEntropyLoss: {:.4f}; MAE: {:.4f}'.format(\n",
    "                        loss.detach().item(), accuracy_mae))    \n",
    "                pbar.update(1)\n",
    "                \n",
    "    predicted_classes = torch.cat(predicted_classes).detach().to('cpu').numpy()\n",
    "    true_classes = torch.cat(true_classes).detach().to('cpu').numpy()\n",
    "    return losses, predicted_classes, true_classes\n",
    "\n",
    "def predict_without_labels(model, test_dataloader, device=\"cuda:0\"):\n",
    "    model.to(device).eval()\n",
    "    predicted_classes = []\n",
    "    step = 0\n",
    "    with tqdm(total=len(test_dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                ids, mask = batch\n",
    "                ids = ids.to(device)\n",
    "                mask = mask.to(device)\n",
    "                \n",
    "                \n",
    "                output = model(ids, token_type_ids=None, \n",
    "                              attention_mask=mask)\n",
    "                predicted = output[0].detach().cpu().numpy()\n",
    "                batch_predicted = np.argmax(predicted, axis=1)\n",
    "                predicted_classes.extend(batch_predicted)\n",
    "                \n",
    "                pbar.set_description(\n",
    "                    'Step: {:.4f}'.format(step))    \n",
    "                pbar.update(1)\n",
    "                step += 1\n",
    "                \n",
    "    return predicted_classes\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, test_dataloader, criterion, \n",
    "          optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
    "    model.to(device)\n",
    "    lrs = []\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoc ‚Ññ', epoch)\n",
    "        print('Train')\n",
    "        train_one_epoch(model, train_dataloader, criterion, optimizer)\n",
    "        torch.save(model.state_dict(), 'model')\n",
    "        print('Model state saved')\n",
    "        print('Validation')\n",
    "        losses, predicted_classes, true_classes = predict(model, \n",
    "                                                          val_dataloader, \n",
    "                                                          criterion)\n",
    "        print('MAE: ', mae(true_classes, predicted_classes))\n",
    "        print('Test')\n",
    "        predicted_classes = predict_without_labels(model, \n",
    "                                                   test_dataloader, \n",
    "                                                   device)\n",
    "        df_answer_kaggle = df_kaggle[\"review_id\"].to_frame()\n",
    "        df_answer_kaggle[\"score\"] = [dict_score_class[item] for item in predicted_classes]\n",
    "        df_answer_kaggle.to_csv(\"data/submission.csv\", index=False)\n",
    "        print('Submission saved')\n",
    " \n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBU9PEXcuA7B"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "learning_rate = 1e-05\n",
    "n_epochs = 3\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prclHgdWv22t"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxhUnBpPuA7C",
    "outputId": "e3d0dffe-c252-4ce5-bcc2-21e4a21108c0"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc ‚Ññ 0\n",
      "Train\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 2.1431; MAE: 0.8458: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2344/2344 [1:00:49<00:00,  1.56s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved\n",
      "Validation\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 1.8889; MAE: 0.9375: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [07:33<00:00,  1.72it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.806612\n",
      "Test\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 624.0000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:02<00:00,  1.73it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n",
      "Epoc ‚Ññ 1\n",
      "Train\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 1.8722; MAE: 0.7125: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2344/2344 [1:00:48<00:00,  1.56s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved\n",
      "Validation\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 1.7562; MAE: 0.6750: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [07:33<00:00,  1.72it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7771239999999999\n",
      "Test\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 624.0000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:02<00:00,  1.72it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n",
      "Epoc ‚Ññ 2\n",
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 2.3880; MAE: 0.9375: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2344/2344 [1:00:57<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved\n",
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 1.7811; MAE: 0.8375: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [07:33<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7456320000000001\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 624.0000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:02<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, test_dataloader, \n",
    "      criterion, optimizer, device, n_epochs, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–≥—Ä—É–∑–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é, –º–æ–∂–Ω–æ –ø—Ä–æ—Ç—ã–∫–∞—Ç—å, –µ—Å–ª–∏ –≤—ã—à–µ –æ–±—ä—è–≤–∏—Ç—å –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å, —Å–∫–∞—á–∞—Ç—å –µ–µ –ø–æ —Å—Å—ã–ª–∫–µ, –∞ –ø–æ—Ç–æ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–µ–π—Ç –∫–æ–º–∞–Ω–¥–æ–π –Ω–∏–∂–µ\n",
    "### –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ª–∏—Ç—å –Ω–∞ –≥–∏—Ç, —Ç–∞–∫ –∫–∞–∫ –≤–µ—Å–∏—Ç –æ—á–µ–Ω—å –º–Ω–æ–≥–æ :(\n",
    "–°—Å—ã–ª–∫–∞ –Ω–∞ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å–∫—É: https://drive.google.com/file/d/1qR2UPEAs6OFdcUUamZLExR8qtSYbd7Tl/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdohoZ45WL4X"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3OeNQkoXHaW"
   },
   "source": [
    "### –ö–æ–Ω—Ç–µ—Å—Ç (–¥–æ 3 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "–ü–æ –∏—Ç–æ–≥–∞–º –≤—Å–µ—Ö –≤–∞—à–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é —Å—á–∏—Ç–∞–µ—Ç–µ –ª—É—á—à–µ–π. –°–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç –≤ –∫–æ–Ω—Ç–µ—Å—Ç. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–µ–≥–æ —Å–∫–æ—Ä–∞ –Ω–∞ –ø—É–±–ª–∏—á–Ω–æ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ, –º—ã –Ω–∞—á–∏—Å–ª–∏–º –≤–∞–º –±–∞–ª–ª—ã:\n",
    "\n",
    " - <0.77 - 3 –±–∞–ª–ª–∞\n",
    " - [0.77; 0.78) - 2 –±–∞–ª–ª–∞\n",
    " - [0.78; 0.8) - 1 –±–∞–ª–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfORFaucXHaW"
   },
   "source": [
    "![](https://i.imgur.com/gCxNpWC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw3_kaggle_(1)_3 (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
